---

marp: true
theme: default
paginate: true
class: invert
math: katex
style: |
  section {
    font-size: 140%;
    width: 1280px;
    height: 720px;
    padding-top: 40px;
    padding-bottom: 40px;
    padding-left: 100px;
    padding-right: 100px;
  }
  ul {
    line-height: 1.2;
  }
  li {
    margin-bottom: 0em;
  }
  pre {
    vertical-align: text-top;
    font-size: 60%;
    line-height: 1.0;
  }
  .columns {
    display: flex;
    gap: 1em;
  }
  .col {
    flex: 1;
  }
  img {
    border-radius: .2em;
  }
footer: ATS &copy; 2025
---

# IRTForests 

<p style="font-size:80%; margin-top:2.5em;">Andrew T. Scott, Fall 2025</p>
<p style="font-size:70%;"><a href="https://github.com/ascott02/IRTForests">github.com/ascott02/IRTForests</a></p>

---

# Item Response Theory + Random Forests

- Trees become respondents, images become items.
- Response matrix records per-tree correctness on held-out examples.
- Goal: explain RF behavior via IRT ability & difficulty signals and vice versa.

---

# Agenda

- Background: IRT Background, RF Background
- Pipeline: Datasets, embeddings, and response matrices powering the studies.
- Case Studies: Baseline CIFAR (PCA), CIFAR (MobileNet), and MNIST.
- Cross-study comparison, takeaways, and next steps.

---

# Why Item Response Theory (IRT)?

**Because performance != ability â€” but theyâ€™re related.**


- Classical Test Theory (CTT) tells us *how someone did on this test.*

- IRT models *how someone would perform on any set of items that measure the same underlying ability*.

- IRT doesnâ€™t replace CTT, it generalizes it with **portable, interpretable measurements** of capability.

<center>

| CTT | IRT |
|-----------------------|----------------------|
| Measures perf. on specific test | Estimates underlying ability |
| Test = sample of items | Items = samples from a calibrated continuum |
| Precision assumed constant | Precision varies with ability |
| Great for grading | Great for understanding and interpretability |

</center>

> A joint calibration framework where ability and difficulty are inferred together, each defined only in relation to the other. Itâ€™s less like grading individuals and more like synchronizing clocks â€” each calibrated against the ensemble.



---


# Item Response Theory Building Blocks

  <div class="col">

## **Core Terms**

- Ability (Î¸): respondent skill; higher â†’ higher success odds.
- Difficulty (Î´): item hardness; higher â†’ harder even for strong respondents.
- Discrimination (ğ‘): slope near Î´ (2PL).
- Guessing (ğ‘): floor for multiple-choice exams (rare here) (3PL).

  </div>
  <div class="col">

## **Translated to Tree Ensemble Analogy**

- Respondents â†’ decision trees on a shared test set.
- Items â†’ images; responses are binary (tree correct?).
- Response matrix $R_{ij} \in \{0,1\}$ feeds variational IRT.
- Outputs: posteriors over Î¸áµ¢, Î´â±¼, and information curves.

  </div>

---

# Rasch (1PL) Model in One Picture

<div class="columns">
  <div class="col">

$$\Pr(R_{ij}=1 \mid \theta_i, \delta_j) = \frac{1}{1 + e^{- (\theta_i - \delta_j)}}$$

- Single global slope keeps parameters on a shared logit scale.
- Î¸ âˆ’ Î´ = 0 â‡’ 50% success; shifts left/right change odds.
- Fisher information peaks where curves are steepest.
- See <a href="https://ascott02.github.io/irt.html">IRT ICC Visualizer</a> for 2PL, 3PL, 4PL

  </div>
  <div class="col" style="text-align:center;">
  <center>
    <img width="85%" src="figures/irt/rasch_curve.png" style="width:100%; border:1px solid #ccc;" />
    <p style="font-size:85%;">1PL Item Characteristic Curves (ICC)</p>
    </center>
  </div>
</div>

---

# IRT Output

- **Ability histograms** flag low-skill trees worth pruning.
- **Difficulty ladders** highlight mislabeled or ambiguous items.
- **Wright maps** overlay Î¸ and Î´ to expose coverage gaps.
- **Information curves** reveal where ensemble confidence is fragile.
- Together they explain *who* struggles and *why*, beyond RF metrics.


---

# Random Forests â€” Many Noisy Trees, One Stable Voice

A **Random Forest** grows lots of trees on **bootstrapped (OOB)** samples  
and **random subsets of features** at each split.

This randomness:
- decorrelates trees â†’ lowers variance,  
- lets each tree explore a different view of the data.

Final prediction = **majority vote** (classification) or **mean** (regression).  

**Margins:** how much more the correct class wins over the runner-up â†’ a measure of confidence.  
**Entropy:** how uncertain the ensemble is â€” low entropy = decisive forest, high entropy = disagreement.

- Trees are fragile storytellers; forests are resilient crowds.  
- Margins and entropy tell you how loudly, and how harmoniously, that crowd speaks.
- Combining both with Î´ surfaces mislabeled or OOD items and tracks curation gains.

---

# Random Forest Margins â€” How Confident Is the Crowd?

$$ \text{margin}(x_i) =
P_{\text{correct}}(x_i)
- \max_{j \neq \text{true}} P_j(x_i) $$

The **margin** measures how far ahead the correct class is
over its nearest competitor.

- **High margin:** trees vote strongly for the right class â†’ confident.  
- **Low or negative margin:** trees disagree or favor another class â†’ uncertain.  

> Think of it as the *vote gap* in an election â€” the wider the gap, the clearer the win.

---

# Ensemble Entropy â€” How Much Do Trees Disagree?

$$ H(x_i) = - \sum_j P_j(x_i) \log_2 P_j(x_i) $$

The **entropy** measures how dispersed the votes are across classes.

- **Low entropy:** trees nearly unanimous â†’ decisive prediction.  
- **High entropy:** votes spread out â†’ uncertainty or class confusion.  

> Within trees, entropy drives splits (purity).  
> Across trees, entropy reveals disagreement â€” the forestâ€™s collective uncertainty.

---

# GenAI in the Loop Scientific Experimentation

- Recursive Prompting, (similar to <a href="https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents">Context Engineering</a>)
- Start from focused `README.md` spec outlining goals, datasets, and diagnostics.
- Automate CLI runs to iterate every experiment end-to-end.
- Promoted results/figures/tables into this deck!
- Commit, push, rinse, and repeat...
- <a href="https://github.com/ascott02/IRTForests">github.com/ascott02/IRTForests</a>

> Plastic tubes and pots and pans
> Bits and pieces and the magic from the hand - Oingo Boingo, "Weird Science" 1985

---


# Pipeline Overview

<div class="columns">
  <div class="col">

**Data Preperation for 3 Experiements**

1. Stratified CIFAR-10 subset: 10k / 2k / 2k splits. Resize 64Ã—64, normalize, PCA â†’ 128-D embeddings.
2. Stratified CIFAR-10 subset: 10k / 2k / 2k splits. Resize 64Ã—64, normalize, MobileNet â†’ 960-D embeddings.
3. MNIST mini: 4k / 800 / 800 digits, normalized 28Ã—28 grayscale. Raw pixels.

**Random Foreset Training**

- RF (2000 trees) trained for every study; metrics and importances saved.
- Response matrices saved: CIFAR `(2000 Ã— 2000)` for PCA & MobileNet, MNIST `(2000 Ã— 800)`.

**IRT Analsysis**
- 1PL Rasch (SVI, 600 epochs) complete for CIFAR+PCA, CIFAR+MobileNet, and MNIST.
- 2PL (SVI, 800 epochs) complete for CIFAR+PCA, CIFAR+MobileNet, and MNIST.
- 3PL (SVI, 1000 epochs) CIFAR MobileNet only.

  </div>
</div>

---

# Datasets Overview

| Dataset | Train | Val | Test | Feature Pipeline | Notes |
|---|---|---|---|---|---|
| CIFAR-10 subset | 10,000 | 2,000 | 2,000 | PCA-128 / MobileNet-V3 (960-D) | Shared splits Study I & II |
| MNIST mini | 4,000 | 800 | 800 | 28Ã—28 grayscale â†’ raw pixels (no PCA) | Control for clean handwriting |

- CIFAR runs differ only by embeddings; labels and splits stay fixed.
- MNIST mirrors the workflow to confirm signals on cleaner data.

---


# Study I Setup: CIFAR-10 + PCA-128

<div class="columns">
  <div class="col">
    <ul>
  <li>Establish the PCA baseline and its uncertainty signals.</li>
  <li>Use IRT to pinpoint weak trees and hard items that motivate stronger features.</li>
  <li>Fixed stratified CIFAR-10 split (10k/2k/2k).</li>
  <li>Resize 64Ã—64, normalize, PCA â†’ 128-D embeddings.</li>
  <li>Train and test 2000 trees.
  <li>Response matrix 2000 Ã— 2000 with mean tree accuracy.</li>
  <li>Artifacts: Metrics, Margins, Entropy, IRT outputs.</li>
    </ul>
  </div>

  <div class="col">
  <center>

<img width="85%" src="figures/datasets/study1_cifar_samples.png" style="width:100%; border:1px solid #ccc;" />
<p style="font-size:85%; text-align:center;">Study I sample grid â€” stratified CIFAR-10 slices</p>
    </center>
  </div>
</div>

---

# Study I Performance (PCA-128)

<center>

| Metric | Value |
|---|---|
| Test / Val / OOB acc | 0.468 / 0.470 / 0.442 |
| Per-class range | 0.260 (bird) â†’ 0.635 (ship) |
| Mean tree accuracy | 0.1763 |
| Mean margin / entropy | 0.0058 / 2.1723 |
| Î´ negatively correlates with margin (Pearson) | âˆ’0.815 |
| Î´ positively correlates with entropy (Pearson) | 0.687 |

</center>

- Baseline ensemble still underperforms due to weak PCA features yet preserves Î´ alignment.
- Margins hover near zero (mean â‰ˆ0.006) and entropy stays high (2.17), signalling broad disagreementâ€”prime for IRT.

---

# Study I Confusion Matrix

<div class="columns">
  <div class="col">
    <img src="figures/rf_confusion_matrix.png" style="width:95%; border:1px solid #ccc;" />
  </div>
  <div class="col">

- Off-diagonal spikes (cat vs dog, bird vs airplane, horse vs deer) mirror high-Î´ items.
- Ships/trucks stay >80% on-diagonal; the highlighted hotspots mark curation targets.

  </div>
</div>

---

# Study I Diagnostics: Ability Profiles

<div class="columns">
  <div class="col">
  <center>
    <img width="85%" src="figures/ability_vs_accuracy.png" style="width:100%; border:1px solid #ccc;" />
    <p style="font-size:85%; text-align:center;">Ability (Î¸) vs tree accuracy â€” Spearman â‰ˆ 0.99</p>
    </center>
  </div>
  <div class="col">
  <center>
  <img width="84%" src="figures/wright_map.png" style="width:95%; border:1px solid #ccc;" />
  <p style="font-size:85%; text-align:center;">Wright map: Î¸ around âˆ’4; Î´ spans roughly [âˆ’0.5, 0.6]</p>
    </center>
  </div>
</div>

- Î¸ spans roughly âˆ’4.7 to âˆ’3.7; a +0.2 shift in ability still separates stronger trees by ~3 pp.
- Î´ clusters near zero but stretches past Â±0.5, flagging the ambiguous animal images against a compressed ability band.

---

# Study I Diagnostics: Î´ vs Error Rate

<div class="columns">
  <div class="col">
    <img src="figures/difficulty_vs_error.png" style="width:95%; border:1px solid #ccc;" />
  </div>
  <div class="col">

- Î´ > 0.4 maps to >80% tree errorâ€”mostly ambiguous animalsâ€”while Î´ < âˆ’0.3 becomes â€œfree points.â€
- Pearson â‰ˆ 0.87, Spearman â‰ˆ 0.86: difficulty doubles as an error heat-map.

  </div>
</div>

---

# Study I Diagnostics: Î´ vs RF Signals

<div class="columns">
  <div class="col">
  <center>
  <img src="figures/difficulty_vs_margin.png" style="width:100%; border:1px solid #ccc;" />
  <p style="font-size:85%;">PCA run: Î´ vs margin (Pearson âˆ’0.82)</p>
    </center>
  </div>
  <div class="col">
  <center>
  <img src="figures/difficulty_vs_entropy.png" style="width:100%; border:1px solid #ccc;" />
  <p style="font-size:85%;">PCA run: Î´ vs entropy (Pearson 0.69)</p>
    </center>
  </div>
</div>

- Hard items cluster bottom-right (low margin, high entropy); opposite corner houses easy wins.
- Study II mirrors the trend with even stronger correlations.

---

# Study I Evidence: Hard vs Easy Examples

<div class="columns">
  <div class="col">

![Hardest items](figures/hardest_items_test.png)

  </div>
  <div class="col">

![Easiest items](figures/easiest_items_test.png)

  </div>
</div>

- Hardest items skew toward ambiguous airplane/ship silhouettes and cluttered cat/dog scenes.
- Easy set is dominated by high-contrast cues (e.g., red fire trucks), yielding low Î´ and entropy.

---

# Study I Takeaways

- Weak PCA features create long tails in both ability (Î¸) and difficulty (Î´), exposing erratic trees.
- Margin and entropy correlate with Î´, but clusters of high-difficulty animals persist across diagnostics.
- Visual inspection confirms mislabeled or low-signal items driving high Î´, motivating feature upgrades.

---

# Study I Fit Checks & Edge Cases

<div class="columns">
  <div class="col">

**Fit diagnostics**

| Metric | Value |
|---|---|
| Item infit Î¼ / p95 | 0.18 / 0.35 |
| Item outfit Î¼ / p95 | 0.18 / 0.34 |
| Tree infit Î¼ / p95 | 0.35 / 0.48 |
| Tree outfit Î¼ / p95 | 0.18 / 0.19 |

- MSQs well below 1 show tree responses are steadier than a pure Rasch prior; |z| never exceeds 0.05.

  </div>
  <div class="col">

**Edge cases worth a look**

- `#118` bird â†’ deer votes (Î´ â‰ˆ 13.4, margin â‰ˆ âˆ’0.05, entropy â‰ˆ 2.28).
- `#1734` truck â†’ cat/frog split (Î´ â‰ˆ 13.2, margin â‰ˆ âˆ’0.09, entropy â‰ˆ 2.27).
- `#1602` horse â†’ dog/horse tie (Î´ â‰ˆ 13.2, margin â‰ˆ âˆ’0.11, entropy â‰ˆ 2.22).

- Each item sits below 9% tree accuracyâ€”prime targets for relabeling or curated augmentations.

<center>
    <img width="60%" src="figures/study1_edge_cases.png" style="width:100%; border:1px solid #ccc; margin-top:0.8em;" />
    <p style="font-size:75%; text-align:center;">Study I edge cases Â· IDs 118, 1734, 1602</p>
</center>

  </div>
</div>

---

# Section II Â· Feature-Rich CIFAR (MobileNet)

- Hold the splits fixed to isolate feature gains.
- Test whether richer embeddings tighten Î¸ spread and retain Î´ alignment.

---

# Study II: CIFAR-10 + MobileNet Embeddings

- Swap PCA features for MobileNet-V3 (960-D) while keeping tree count and splits constant.
- Compare RF metrics, uncertainty signals, and IRT parameters against the baseline.

---

# Study II Setup: CIFAR-10 + MobileNet-V3

<div class="columns">
  <div class="col">
    <ul>
  <li>Reuse Study I splits to isolate feature effects.</li>
  <li>Extract 960-D MobileNet-V3 Small embeddings (`data/cifar10_mobilenet_embeddings.npz`).</li>
  <li>Response matrix 2000 Ã— 2000 with mean tree accuracy 0.479.</li>
  <li>Artifacts live under `data/mobilenet/*` and `figures/mobilenet/`.</li>
    </ul>
  </div>
  <div class="col">
    <img src="figures/datasets/study2_cifar_samples.png" style="width:100%; border:1px solid #ccc;" />
    <p style="font-size:85%; text-align:center;">Study II sample grid â€” same splits, MobileNet embeddings</p>
  </div>
</div>

---

# Study II Performance (MobileNet-V3)

| Metric | Value |
|---|---|
| Test / Val / OOB acc | 0.819 / 0.820 / 0.812 |
| Per-class range | 0.695 (bird) â†’ 0.925 (ship) |
| Mean tree accuracy | 0.4792 |
| Mean margin / entropy | 0.2806 / 1.4929 |
| Î´ negatively correlates with margin (Pearson) | âˆ’0.950 |
| Î´ positively correlates with entropy (Pearson) | 0.881 |

- Pretrained features boost accuracy by 35 pp while strengthening Î´ correlations.
- Higher margins and lower entropy show confidence gains except on stubborn animal classes.
- Artifacts: metrics, response matrix, signals, and IRT outputs under `data/mobilenet/`.

---

# Study II Diagnostics: Î´ vs RF Signals

<div class="columns">
  <div class="col">
  <center>
    <img width="85%" src="figures/mobilenet/mobilenet_difficulty_vs_margin.png" style="width:100%; border:1px solid #ccc;" />
  <p style="font-size:85%;">Î´ vs margin (Pearson âˆ’0.95)</p>
  </center>
  </div>
  <div class="col">
  <center>
    <img width="85%" src="figures/mobilenet/mobilenet_difficulty_vs_entropy.png" style="width:100%; border:1px solid #ccc;" />
  <p style="font-size:85%;">Î´ vs entropy (Pearson 0.88)</p>
  </center>
  </div>
</div>

- MobileNet compresses the easy cluster (high margin, low entropy) while isolating true hard cases.
- Larger |corr| values show tighter agreement between Î´ and RF uncertainty.
- Cat/dog confusions persist, marking curation targets.

---

# Study II Diagnostics: Ability Profiles

<div class="columns">
  <div class="col">
  <center>
    <img width="85%" src="figures/mobilenet/ability_vs_accuracy.png" style="width:100%; border:1px solid #ccc;" />
  <p style="font-size:85%; text-align:center;">Ability (Î¸) vs tree accuracy â€” Pearson 0.96</p>
  </center>
  </div>
  <div class="col">
  <center>
    <img width="84%%" src="figures/mobilenet/wright_map.png" style="width:100%; border:1px solid #ccc;" />
  <p style="font-size:85%; text-align:center;">Wright map: Î¸ â‰ˆ âˆ’0.46 Â± 0.23; Î´ spans Â±2.1</p>
  </center>
  </div>
</div>

- Î¸ mean âˆ’0.46 Â± 0.23 keeps the ensemble tightly banded while still ranking trees cleanly.
- Ability remains tied to per-tree accuracy, so feature qualityâ€”rather than tree diversityâ€”now caps gains.

---

# Study II Diagnostics: Î´ vs Error Rate

<div class="columns">
  <div class="col">
    <img src="figures/mobilenet/difficulty_vs_error.png" style="width:95%; border:1px solid #ccc;" />
  </div>
  <div class="col">

- Pearson 0.99 keeps Î´ aligned with mean tree error even at the higher accuracy ceiling.
- Hardest items (Î´ > 1.5) persistâ€”mostly cat/dog overlaps and ambiguous aircraftâ€”while the easy zone (Î´ < âˆ’1) expands.

  </div>
</div>

---

# Study II Evidence: Hard vs Easy Examples

<div class="columns">
  <div class="col">

![MobileNet hardest items](figures/mobilenet/hardest_items_test.png)

  </div>
  <div class="col">

![MobileNet easiest items](figures/mobilenet/easiest_items_test.png)

  </div>
</div>

- MobileNet tightens easy clusters yet the same cat/dog outliers survive with Î´ > 1.5.
- Easy wins sharpen into high-contrast ships and trucks, showing how feature upgrades cleanly separate low-Î´ items.

---

# Study II Takeaways

- MobileNet embeddings add 35 pp of accuracy while maintaining a focused ability band (Std(Î¸) â‰ˆ 0.23).
- Î´ stays aligned with RF uncertainty, isolating a smaller yet stubborn ambiguous cluster.
- Residual cat/dog confusion points to data curation as the next lever.

---

# Study II Fit Checks & Edge Cases

<div class="columns">
  <div class="col">

**Fit diagnostics**

| Metric | Value |
|---|---|
| Item infit Î¼ / p95 | 0.27 / 0.37 |
| Item outfit Î¼ / p95 | 0.27 / 0.37 |
| Tree infit Î¼ / p95 | 0.29 / 0.31 |
| Tree outfit Î¼ / p95 | 0.27 / 0.29 |

- Narrow MSQ spread (â‰¤0.37) confirms MobileNet trees behave consistently; no misfit flags at |z| > 0.05.

  </div>
  <div class="col">

**Edge cases worth a look**

- `#1190` automobile â†’ frog votes (Î´ â‰ˆ 15.4, margin â‰ˆ âˆ’0.22, entropy â‰ˆ 1.85; top probs frog 0.28, deer 0.27).
- `#1196` bird â†’ horse (Î´ â‰ˆ 14.9, margin â‰ˆ âˆ’0.38, entropy â‰ˆ 1.31; horse 0.41, deer 0.41, bird 0.08).
- `#95` frog â†’ bird (Î´ â‰ˆ 14.8, margin â‰ˆ âˆ’0.25, entropy â‰ˆ 1.89; bird 0.32, deer 0.20, frog 0.17).

- These persistent outliers survive the feature upgradeâ€”queue them for image/label review next.
<center>
    <img width="60%" src="figures/study2_edge_cases.png" style="width:100%; border:1px solid #ccc; margin-top:0.8em;" />
    <p style="font-size:75%; text-align:center;">Study II edge cases Â· IDs 1190, 1196, 95</p>
</center>

  </div>
</div>

---


# Section III Â· Control Study (MNIST)

- Probe the pipeline on a high-signal, low-noise dataset.
- Confirm that IRT still mirrors RF uncertainty when accuracy is near perfect.

---

# Study III: MNIST Mini-Study

- Lightweight handwriting dataset to validate RF Ã— IRT beyond CIFAR-10.
- Acts as a control where ambiguity is rare yet still detectable.

---

# Study III Setup: MNIST Mini-Study

<div class="columns">
  <div class="col">
    <ul>
  <li>Split 4k / 800 / 800 digits with stratified sampling and a fixed seed.</li>
  <li>Flatten 28Ã—28 grayscale digits; no augmentation.</li>
  <li>Train a 2000-tree RF on raw pixels; response matrix 2000 Ã— 800.</li>
  <li>Artifacts land in `data/mnist/` with plots in `figures/mnist/`.</li>
    </ul>
  </div>
  <div class="col">
    <img src="figures/datasets/mnist_samples.png" style="width:100%; border:1px solid #ccc;" />
    <p style="font-size:85%; text-align:center;">Study III sample grid â€” curated MNIST mini split</p>
  </div>
</div>

---

# Study III Performance (MNIST)

| Metric | Value |
|---|---|
| Train / Val / Test | 4000 / 800 / 800 |
| RF test / val / OOB | 0.954 / 0.944 / 0.939 |
| Mean margin / entropy | 0.5644 / 1.0768 |
| Î´ negatively correlates with margin (Pearson) | âˆ’0.975 |
| Î´ positively correlates with entropy (Pearson) | 0.970 |
| Î¸ mean Â± std | 3.04 Â± 0.29 |
| Î´ mean Â± std | âˆ’0.13 Â± 0.47 |

- Ambiguous digits (e.g., brushed 5 vs 6) still spike Î´ toward the positive tail; elsewhere the forest is decisive.
- Low entropy + high margin line up with low Î´, giving a â€œsanity benchmarkâ€ beyond CIFAR.

---

# Study III Diagnostics: Î´ vs RF Signals

<div class="columns">
  <div class="col">
    <img src="figures/mnist/mnist_difficulty_vs_margin.png" style="width:100%; border:1px solid #ccc;" />
  <p style="font-size:85%;">Î´ vs margin (Pearson âˆ’0.97)</p>
  </div>
  <div class="col">
    <img src="figures/mnist/mnist_difficulty_vs_entropy.png" style="width:100%; border:1px solid #ccc;" />
  <p style="font-size:85%;">Î´ vs entropy (Pearson 0.97)</p>
  </div>
</div>

- Clean digits show near-perfect alignment between Î´ and RF uncertainty.
- Only a handful of Î´ > 1.2 digits drive the residual uncertainty (stroke collisions like 3/5, 4/9).

---

# Study III Diagnostics: Ability Profiles

<div class="columns">
  <div class="col">
  <center>
    <img width="75%" src="figures/mnist/ability_vs_accuracy.png" style="width:100%; border:1px solid #ccc;" />
  <p style="font-size:85%; text-align:center;">Ability (Î¸) vs tree accuracy â€” Pearson 0.98</p>
  </center>
  </div>
  <div class="col">
  <center>
    <img width="74%" src="figures/mnist/wright_map.png" style="width:100%; border:1px solid #ccc;" />
  <p style="font-size:85%; text-align:center;">Wright map: Î¸ mean 3.04 Â± 0.29; Î´ mean âˆ’0.13 Â± 0.47</p>
  </center>
  </div>
</div>

- Î¸ mean 3.04 Â± 0.29 shows strong consensus, while Î´ mean âˆ’0.13 Â± 0.47 keeps a modest positive tail for ambiguous strokes.
- Shared scales expose plentiful easy wins with only a few sharp spikesâ€”opposite of the CIFAR baseline.


---

# Study III Diagnostics: Î´ vs Error Rate

<div class="columns">
  <div class="col">
    <img src="figures/mnist/difficulty_vs_error.png" style="width:95%; border:1px solid #ccc;" />
  </div>
  <div class="col">

- Pearson 0.98 keeps Î´ tied to mean tree error despite the high accuracy ceiling.
- Î´ > 1.2 corresponds to stroke-collided 3/5/8 and 4/9 pairs; the long negative tail is trivial for the ensemble.

  </div>
</div>

---

# Study III Evidence: Hard vs Easy Digits

<div class="columns">
  <div class="col">

![MNIST hardest digits](figures/mnist/hardest_digits_test.png)

  </div>
  <div class="col">

![MNIST easiest digits](figures/mnist/easiest_digits_test.png)

  </div>
</div>

- Hardest digits show stroke collisions (3 vs 5, 4 vs 9) that push Î´ above 1 despite high margins elsewhere.
- Easy digits are crisp, centered strokesâ€”useful anchors when explaining why Î´ plunges on most of the dataset.

---

# Study III Takeaways

- Î´ and RF uncertainty agree almost perfectly, while Î¸ stays high yet still flags the rare ambiguous strokes.
- The control study confirms the RF Ã— IRT pipeline holds outside noisy vision data.

---

# Study III Fit Checks & Edge Cases

<div class="columns">
  <div class="col">

**Fit diagnostics**

<center>

| Metric | Value |
|---|---|
| Item infit Î¼ / p95 | 0.23 / 0.38 |
| Item outfit Î¼ / p95 | 0.22 / 0.37 |
| Tree infit Î¼ / p95 | 0.30 / 0.32 |
| Tree outfit Î¼ / p95 | 0.22 / 0.25 |
</center>

- Rasch residuals stay tight (|z| < 0.07), confirming the control studyâ€™s consistency.

  </div>
  <div class="col">

**Edge cases worth a look**

- `#296` digit 0 â†’ vote 7 (Î´ â‰ˆ 17.6, margin â‰ˆ âˆ’0.35, entropy â‰ˆ 1.83; top probs 7=0.38, 9=0.18, 4=0.16).
- `#151` digit 9 â†’ vote 6 (Î´ â‰ˆ 17.3, margin â‰ˆ âˆ’0.34, entropy â‰ˆ 1.93; top probs 6=0.39, 5=0.12, 2=0.10).
- `#708` digit 4 â†’ vote 3 (Î´ â‰ˆ 16.3, margin â‰ˆ âˆ’0.08, entropy â‰ˆ 2.10; top probs 3=0.19, 4=0.18, 9=0.15).

- Archive these strokes for a â€œconfusing digitsâ€ gallery or curation playbook.

<center>
    <img width="60%" src="figures/study3_edge_cases.png" style="width:100%; border:1px solid #ccc; margin-top:0.8em;" />
    <p style="font-size:75%; text-align:center;">Study III edge cases Â· IDs 296, 151, 708</p>
<center>

  </div>
</div>

---

# Section IV Â· Cross-Study & Diagnostics

- Compare backbones and datasets on a shared Î¸/Î´ scale.
- Surface recurring themes before the close.

---

# Cross-Study Snapshot

| Study | Feature Backbone | Test Acc | Î´ negatively correlates with margin (Pearson) | Î´ positively correlates with entropy (Pearson) | Std(Î¸) | Std(Î´) |
|---|---|---|---|---|---|---|
| Study I: CIFAR + PCA-128 | PCA-128 | 0.468 | âˆ’0.815 | 0.687 | 0.154 | 0.150 |
| Study II: CIFAR + MobileNet | MobileNet-V3 (960-D) | 0.819 | âˆ’0.950 | 0.881 | 0.228 | 0.871 |
| Study III: MNIST Mini | Raw pixels | 0.954 | âˆ’0.975 | 0.970 | 0.289 | 0.472 |

- <small>*Std(Î¸) measures tree ability spread; Std(Î´) measures item difficulty spread.*</small>

- Across studies Î´ remains negatively correlated with margin and positively correlated with entropy: PCA lands near âˆ’0.82, MobileNet tightens to âˆ’0.95, and MNIST saturates the scale at âˆ’0.98.
- Î¸ spread remains compact (Std(Î¸) â‰ˆ 0.15â€“0.29) even with 2000 trees; MobileNet widens slightly as headroom grows.
- Difficulty variance balloons on MobileNet (Std(Î´) â‰ˆ 0.87) while MNIST stays moderate, underscoring how rich features surface nuanced â€œhardâ€ digits.

---

# Cross-Study Fit Snapshot

| Study | Item infit Î¼ / p95 | Item outfit Î¼ / p95 | Tree infit Î¼ / p95 | Tree outfit Î¼ / p95 |
|---|---|---|---|---|
| CIFAR + PCA | 0.18 / 0.35 | 0.18 / 0.34 | 0.35 / 0.48 | 0.18 / 0.19 |
| CIFAR + MobileNet | 0.27 / 0.37 | 0.27 / 0.37 | 0.29 / 0.31 | 0.27 / 0.29 |
| MNIST mini | 0.23 / 0.38 | 0.22 / 0.37 | 0.30 / 0.32 | 0.22 / 0.25 |

- All MSQs stay well below 1, indicating over-dispersed errors are rare and Rasch assumptions hold after 2000-tree scaling.
- MobileNetâ€™s slight lift in item MSQ reflects richer feature diversity, while MNIST keeps both item and tree fits exceptionally tight.

---

# 2PL Discrimination (CIFAR + PCA)

- 800-epoch 2PL fit (lr 0.02) yields mean ğ‘ â‰ˆ **0.35 Â± 0.10** (range 0.07â€“0.71).
- ğ‘ correlates with margin at **âˆ’0.83** and with entropy at **+0.63**, aligning slope with RF uncertainty signals.
- Discrimination peaks on the low-margin, high-entropy animal items and steadily tapers for easier scenes, leaving high-margin images with softer slopes.

<div class="columns">
  <div class="col">

  <center>
    <img width="85%" src="figures/2pl_discrimination_vs_margin.png" style="width:100%; border:1px solid #ccc;" />
  </center>
  </div>
  <div class="col">

  <center>
    <img width="85%" src="figures/2pl_discrimination_vs_entropy.png" style="width:100%; border:1px solid #ccc;" />
  </center>
  </div>
</div>

---

# 2PL Discrimination (CIFAR + MobileNet)

- Mean ğ‘ settles at **0.27 Â± 0.15** with a modest tail (max â‰ˆ1.16).
- ğ‘ correlates with margin at **âˆ’0.32** and with entropy at **+0.10**, keeping residual cat/dog confusion in focus while the easy cluster sharpens.
- Discrimination concentrates in the tails: hard animal confusions and trivially easy scenes separate trees, while mid-uncertainty items contribute little.

<div class="columns">
  <div class="col">

  <center>
    <img width="85%" src="figures/mobilenet_2pl_discrimination_vs_margin.png" style="width:100%; border:1px solid #ccc;" />
  </center>
  </div>
  <div class="col">

  <center>
    <img width="85%" src="figures/mobilenet_2pl_discrimination_vs_entropy.png" style="width:100%; border:1px solid #ccc;" />
  </center>
  </div>
</div>


---

# 2PL Discrimination (MNIST)

- Mean ğ‘ lifts to **0.33 Â± 0.25**, so only a modest slice of digits remains truly separating despite the high accuracy ceiling.
- ğ‘ correlates with margin at **+0.89** while its correlation with entropy flips to **âˆ’0.96**â€”uncertainty vanishes outside the awkward strokes.
- Discrimination climbs with margin and falls with entropy: crisp, easy digits carry the steepest slopes while ambiguous stroke collisions stay much flatter.

<div class="columns">
  <div class="col">

  <center>
    <img width="85%" src="figures/mnist_2pl_discrimination_vs_margin.png" style="width:100%; border:1px solid #ccc;" />
  </center>
  </div>
  <div class="col">

  <center>
    <img width="85%" src="figures/mnist_2pl_discrimination_vs_entropy.png" style="width:100%; border:1px solid #ccc;" />
  </center>
  </div>
</div>

---

# 3PL Pilot Â· MobileNet

- 1k-epoch 3PL run (lr 0.01) lands at guess mean **0.35 Â± 0.16**.
- Î¸ vs accuracy stays tight (Pearson **0.98**); slopes average **0.32 Â± 0.08** with a broader tail.
- High guess mass piles onto the ambiguous animal scenes (low margin, high entropy), reinforcing the â€œguessingâ€ narrative.

<div class="columns">
  <div class="col">
    <img src="figures/mobilenet_3pl_guess_hist.png" style="width:100%; border:1px solid #ccc;" />
    <p style="font-size:72%; text-align:center;">3PL MobileNet Â· Guess distribution</p>
  </div>
  <div class="col">
    <img src="figures/mobilenet_3pl_guess_vs_margin.png" style="width:100%; border:1px solid #ccc;" />
    <p style="font-size:72%; text-align:center;">3PL MobileNet Â· Guess vs Margin (colored by entropy)</p>
  </div>
</div>

---

# Tree Attribute Correlations

- MobileNet: Pearson corr. (leaf count, Î¸) **âˆ’0.78**; (OOB accuracy, Î¸) **+0.75**â€”shallow, accurate trees shine.
- PCA baseline: Pearson corr. (leaf count, Î¸) **âˆ’0.20**; (OOB accuracy, Î¸) **+0.28**; MNIST shows similar leaf penalties (âˆ’0.47).

<div class="columns">
  <div class="col">

  <center>
    <img width="85%" src="figures/mobilenet_tree_oob_accuracy_vs_theta.png" style="width:100%; border:1px solid #ccc;" />
  </center>
  </div>
  <div class="col">

  <center>
    <img width="85%" src="figures/pca_tree_n_leaves_vs_theta.png" style="width:100%; border:1px solid #ccc;" />
  </center>
  </div>
</div>


---

# Key Takeaways

- IRT and RF still move in lockstep: Î¸ tracks per-tree accuracy, while Î´ and ğ‘ surface stubborn item pockets.
- MobileNetâ€™s discrimination tail isolates animal confusions despite stronger features; MNIST flips signs because mistakes are rare.
- 3PL adds a modest guessing floor (~0.25) without upsetting Î¸â€“accuracy alignment.
- Tree attributes expose pruning cues: shallow, high-OOB trees consistently land higher Î¸.

---

# Next Steps

- Fold discrimination stats into `reports/embedding_comparison.md` & deck tables for quick grabs.
- Run stability sweeps (50/100 trees, alternate seeds) to quantify variance in ğ‘ and Î¸.
- Decide whether 3PL merits extension to PCA/MNIST or documenting as MobileNet-only.
- Finish item-tier overlays (high/medium/low ğ‘) and align them with the qualitative grids.

--- 

# Decision Trees â€” From Data to Splits

<div class="columns">
  <div class="col">

**Idea:** recursively split data to  increase *purity* of labels.  

Example:  
> â€œPetalLength < 2.5?â€ â†’ all *Setosa* left, others right.

At each node:
- compute **impurity** (e.g., *entropy* or *Gini*):
  $$ H = -\sum_i p_i \log_2 p_i $$
- choose the split that **maximally reduces impurity** â€” i.e. makes groups more uniform.  

A single tree = a set of *ifâ€“then* rules that classify or predict.
  </div>

  <div class="col">

<div class="col">

<center>

| PetalLength | PetalWidth | Species |
|--------------|-------------|----------|
| 1.4 | 0.2 | Setosa |
| 4.7 | 1.4 | Versicolor |
| 5.5 | 2.0 | Virginica |

<br />
<br />
<img width="65%" src="iris.svg">

</center>
</div>

</div>


---

# Gini vs. Entropy â€” Two Lenses on Node Impurity

<div class="columns">
<div class="col">

**Entropy (Information Theory):**

$$ H = - \sum_i p_i \log_2 p_i $$

Measures **uncertainty** â€”  expected information (in bits) needed to classify a random sample.  *High when classes are evenly mixed.*
</div>

<div class="col">

**Gini Impurity (Probability of Misclassification):**

$$ G = 1 - \sum_i p_i^2 $$

Measures **chance of error** â€”  probability that two randomly drawn samples from the node  belong to different classes.
</div>
</div>


<center>

| Metric | Theoretical Lens | Interpretation | Typical Use |
|---------|------------------|----------------|--------------|
| **Entropy** | Information theory | â€œHow surprised would I be?â€ | ID3, C4.5 trees |
| **Gini** | Probability theory | â€œHow often would I be wrong?â€ | CART trees, scikit-learn default |
</center>

> Both peak when classes are perfectly mixed (p = 0.5).  
> Gini is slightly flatter â€” faster to compute, less sensitive to extremes.


