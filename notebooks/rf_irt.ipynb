{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9301c25",
   "metadata": {},
   "source": [
    "# Random Forest × IRT Study\n",
    "\n",
    "This notebook walks through data preparation, model training, and Item Response Theory analysis for the CIFAR-10 subset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06d7d36",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "\n",
    "Import libraries, define configuration, and set deterministic seeds for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eae4be01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:20:35.884525Z",
     "iopub.status.busy": "2025-10-13T05:20:35.884424Z",
     "iopub.status.idle": "2025-10-13T05:20:36.444298Z",
     "shell.execute_reply": "2025-10-13T05:20:36.444005Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "DATA_ROOT = PROJECT_ROOT / \"data\"\n",
    "CACHE_DIR = DATA_ROOT\n",
    "FIGURES_DIR = PROJECT_ROOT / \"figures\"\n",
    "MODELS_DIR = PROJECT_ROOT / \"models\"\n",
    "SUBSET_ARCHIVE = DATA_ROOT / \"cifar10_subset.npz\"\n",
    "EMBEDDINGS_ARCHIVE = DATA_ROOT / \"cifar10_embeddings.npz\"\n",
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# TODO: when executing, ensure directories exist before writing outputs.\n",
    "# FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "# MODELS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0928909",
   "metadata": {},
   "source": [
    "## 1. Data Download & Subsampling\n",
    "\n",
    "Use the helper routines in `src.data_pipeline` to ensure CIFAR-10 is downloaded and stratified into manageable train/val/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67428c6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:20:36.445693Z",
     "iopub.status.busy": "2025-10-13T05:20:36.445522Z",
     "iopub.status.idle": "2025-10-13T05:20:37.540481Z",
     "shell.execute_reply": "2025-10-13T05:20:37.540274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ascott/ascott_from_rey/ascott_svn/SFSU/Fall_2025/research/IRTForests/data/cifar10_subset.npz')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_pipeline import SubsetConfig, save_cifar10_subset\n",
    "\n",
    "subset_config = SubsetConfig(data_root=CACHE_DIR)\n",
    "if not SUBSET_ARCHIVE.exists():\n",
    "    subset_archive = save_cifar10_subset(subset_config)\n",
    "else:\n",
    "    subset_archive = SUBSET_ARCHIVE\n",
    "subset_archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ecdec",
   "metadata": {},
   "source": [
    "## 2. Embedding Pipeline\n",
    "\n",
    "Flatten the cached tensors and project to a compact latent space with PCA to serve as Random Forest inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33e9b154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:20:37.541578Z",
     "iopub.status.busy": "2025-10-13T05:20:37.541414Z",
     "iopub.status.idle": "2025-10-13T05:20:37.543754Z",
     "shell.execute_reply": "2025-10-13T05:20:37.543546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_embeddings': None,\n",
       " 'val_embeddings': None,\n",
       " 'test_embeddings': None,\n",
       " 'explained_variance_ratio': None}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_pipeline import compute_pca_embeddings\n",
    "\n",
    "if not EMBEDDINGS_ARCHIVE.exists():\n",
    "    embeddings_path, embedding_summary = compute_pca_embeddings(subset_archive)\n",
    "else:\n",
    "    embeddings_path, embedding_summary = EMBEDDINGS_ARCHIVE, {\n",
    "        'train_embeddings': None,\n",
    "        'val_embeddings': None,\n",
    "        'test_embeddings': None,\n",
    "        'explained_variance_ratio': None,\n",
    "    }\n",
    "embedding_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fa1c12",
   "metadata": {},
   "source": [
    "## 3. Random Forest Training\n",
    "\n",
    "Train a baseline `RandomForestClassifier` on the PCA embeddings and capture core metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff2f8564",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:20:37.544557Z",
     "iopub.status.busy": "2025-10-13T05:20:37.544479Z",
     "iopub.status.idle": "2025-10-13T05:20:37.550228Z",
     "shell.execute_reply": "2025-10-13T05:20:37.550032Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "embeddings = np.load(embeddings_path)\n",
    "X_train = embeddings['train_embeddings']\n",
    "X_val = embeddings['val_embeddings']\n",
    "X_test = embeddings['test_embeddings']\n",
    "y_train = embeddings['y_train']\n",
    "y_val = embeddings['y_val']\n",
    "y_test = embeddings['y_test']\n",
    "\n",
    "# TODO (execution phase): optionally standardize embeddings.\n",
    "# if not embeddings.get('whitened', False):\n",
    "#     scaler = StandardScaler().fit(X_train)\n",
    "#     X_train = scaler.transform(X_train)\n",
    "#     X_val = scaler.transform(X_val)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "#     np.savez(CACHE_DIR / 'embedding_scaler.npz', mean_=scaler.mean_, scale_=scaler.scale_)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    oob_score=True,\n",
    ")\n",
    "\n",
    "# Execution checklist (leave commented until ready):\n",
    "# 1. rf.fit(X_train, y_train)\n",
    "# 2. y_pred = rf.predict(X_test)\n",
    "# 3. probas = rf.predict_proba(X_test)\n",
    "# 4. metrics = {\n",
    "#        'overall_accuracy': float(accuracy_score(y_test, y_pred)),\n",
    "#        'oob_accuracy': float(rf.oob_score_),\n",
    "#        'val_accuracy': float(accuracy_score(y_val, rf.predict(X_val))),\n",
    "#        'per_class_accuracy': accuracy_score(y_test, y_pred, normalize=False)  # adjust to per-class table\n",
    "#    }\n",
    "# 5. conf_mat = confusion_matrix(y_test, y_pred)\n",
    "# 6. permutation = permutation_importance(\n",
    "#        rf, X_val, y_val, n_repeats=10, random_state=SEED, n_jobs=-1\n",
    "#    )\n",
    "# 7. persist metrics/arrays to CACHE_DIR / 'rf_metrics.json' and 'rf_confusion.npy'.\n",
    "# 8. dump feature importances & permutation results for slide consumption.\n",
    "\n",
    "# Suggested persistence stub:\n",
    "# metrics_payload = {\n",
    "#     'metrics': metrics,\n",
    "#     'classes': embeddings['classes'].tolist(),\n",
    "#     'feature_importances': rf.feature_importances_.tolist(),\n",
    "# }\n",
    "# (CACHE_DIR / 'rf_metrics.json').write_text(json.dumps(metrics_payload, indent=2))\n",
    "# np.save(CACHE_DIR / 'rf_confusion.npy', conf_mat)\n",
    "# permutation_df = pd.DataFrame(\n",
    "#     {'feature': np.arange(permutation.importances_mean.size),\n",
    "#      'importances_mean': permutation.importances_mean,\n",
    "#      'importances_std': permutation.importances_std}\n",
    "# )\n",
    "# permutation_df.to_csv(CACHE_DIR / 'rf_permutation_importance.csv', index=False)\n",
    "\n",
    "# Visualization hook (to be run later):\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig, ax = plt.subplots(figsize=(6, 5))\n",
    "# sns.heatmap(conf_mat / conf_mat.sum(axis=1, keepdims=True), annot=True, fmt='.2f', ax=ax)\n",
    "# ax.set_title('Random Forest Confusion Matrix (Normalized)')\n",
    "# ax.set_xlabel('Predicted')\n",
    "# ax.set_ylabel('True')\n",
    "# fig.tight_layout()\n",
    "# fig_path = FIGURES_DIR / 'rf_confusion_matrix.png'\n",
    "# FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "# fig.savefig(fig_path, dpi=200)\n",
    "# plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36404428",
   "metadata": {},
   "source": [
    "## 4. Response Matrix Construction\n",
    "\n",
    "Collect per-tree predictions on the test split to assemble the binary response matrix `R`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f35d4bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:20:37.551253Z",
     "iopub.status.busy": "2025-10-13T05:20:37.551175Z",
     "iopub.status.idle": "2025-10-13T05:20:37.552964Z",
     "shell.execute_reply": "2025-10-13T05:20:37.552809Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Response matrix utility --------------------------------------------------\n",
    "# TODO: ensure RF is trained before running this section.\n",
    "# response_matrix shape: (n_trees, n_test_examples)\n",
    "# Each entry is 1 if estimator predicts correctly, else 0.\n",
    "\n",
    "def build_response_matrix(rf_model, X, y_true):\n",
    "    \"\"\"Return binary matrix of estimator correctness for each test example.\"\"\"\n",
    "    responses = []\n",
    "    for estimator in rf_model.estimators_:\n",
    "        preds = estimator.predict(X)\n",
    "        responses.append((preds == y_true).astype(np.uint8))\n",
    "    return np.stack(responses)\n",
    "\n",
    "# Execution plan (commented for now):\n",
    "# R = build_response_matrix(rf, X_test, y_test)\n",
    "# response_path = CACHE_DIR / 'response_matrix.npz'\n",
    "# np.savez(response_path, R=R, y_test=y_test, classes=embeddings['classes'])\n",
    "# Wright-map compatible summary stats:\n",
    "# item_accuracy = R.mean(axis=0)\n",
    "# tree_accuracy = R.mean(axis=1)\n",
    "# summary = {\n",
    "#     'item_accuracy': item_accuracy.tolist(),\n",
    "#     'tree_accuracy': tree_accuracy.tolist(),\n",
    "# }\n",
    "# (CACHE_DIR / 'response_summary.json').write_text(json.dumps(summary, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c4ce4",
   "metadata": {},
   "source": [
    "## 5. IRT Fitting\n",
    "\n",
    "Fit a Rasch (1PL) model using the response matrix to estimate tree ability (θ) and item difficulty (δ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6a426c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:20:37.553787Z",
     "iopub.status.busy": "2025-10-13T05:20:37.553698Z",
     "iopub.status.idle": "2025-10-13T05:20:37.555074Z",
     "shell.execute_reply": "2025-10-13T05:20:37.554940Z"
    }
   },
   "outputs": [],
   "source": [
    "# IRT fitting checklist ----------------------------------------------------\n",
    "# Preferred library: py_irt (fallback: pyirt). Expect binary matrix input.\n",
    "# Example workflow once R is available:\n",
    "# from py_irt.irt import irt_1pl\n",
    "# model = irt_1pl(R)\n",
    "# tree_ability = model['theta']           # shape (n_trees,)\n",
    "# item_difficulty = model['delta']        # shape (n_items,)\n",
    "# discrimination = model.get('a')         # optional for 2PL\n",
    "# log_likelihood = model.get('loglik')\n",
    "#\n",
    "# Diagnostics to capture:\n",
    "# - Convergence flag / iterations\n",
    "# - Mean/std of θ and δ\n",
    "# - Histogram-ready arrays saved to CACHE_DIR / 'irt_parameters.npz'\n",
    "#\n",
    "# Suggested persistence stub:\n",
    "# np.savez(\n",
    "#     CACHE_DIR / 'irt_parameters.npz',\n",
    "#     theta=tree_ability,\n",
    "#     delta=item_difficulty,\n",
    "#     a=discrimination,\n",
    "#     meta={'loglik': log_likelihood}\n",
    "# )\n",
    "# Additionally, emit JSON summary for slides/reporting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bab86f6",
   "metadata": {},
   "source": [
    "## 6. Comparative Analysis\n",
    "\n",
    "Contrast IRT parameters with Random Forest margins, feature importances, and error patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c27eceab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:20:37.555664Z",
     "iopub.status.busy": "2025-10-13T05:20:37.555603Z",
     "iopub.status.idle": "2025-10-13T05:20:37.556975Z",
     "shell.execute_reply": "2025-10-13T05:20:37.556711Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: compute correlations, Wright map visualization, and hard example list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f0c321",
   "metadata": {},
   "source": [
    "## 7. Slide Export\n",
    "\n",
    "Append generated plots and key findings to `slides.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0bc25bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:20:37.557736Z",
     "iopub.status.busy": "2025-10-13T05:20:37.557662Z",
     "iopub.status.idle": "2025-10-13T05:20:37.559044Z",
     "shell.execute_reply": "2025-10-13T05:20:37.558881Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: once RF + IRT outputs are ready, assemble comparison plots.\n",
    "# Suggested steps:\n",
    "# 1. Compute RF margin per example from `probas` gathered above (p_true - max_other).\n",
    "#    margins = probas[np.arange(len(y_test)), y_test] - np.max(np.where(one_hot_indices != y_test[:, None], probas, -np.inf), axis=1)\n",
    "# 2. Build a dataframe with columns ['delta', 'margin', 'entropy', 'class', 'hard_example_flag'].\n",
    "# 3. Correlate item difficulty δ with margin, entropy, per-class error, and RF confidence.\n",
    "#    store both Pearson and Spearman correlations in CACHE_DIR / 'correlations.json'.\n",
    "# 4. Produce Wright map with matplotlib/seaborn; save to FIGURES_DIR / 'wright_map.png'.\n",
    "#    Example: twin histogram or scatter aligning θ (trees) on top axis and δ (items) on bottom axis.\n",
    "# 5. Surface top-10 hardest items (largest δ) along with thumbnails (use original tensors).\n",
    "#    Persist indices to CACHE_DIR / 'hard_items.json' and copy images to FIGURES_DIR / hard_examples/.\n",
    "# 6. Summarize findings in dictionaries to feed slides export and README logs.\n",
    "# 7. Persist correlation table to CSV for reproducibility; include ranking of trees/items by ability/difficulty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7a3068",
   "metadata": {},
   "source": [
    "## New analytics: RF margins, δ correlations, visuals\n",
    "\n",
    "Run helper scripts to compute RF per-item signals, correlate them with IRT difficulty, and emit supporting figures (difficulty vs margin/entropy, Wright map, hardest/easiest montages, class difficulty summary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e89f3b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:20:37.559610Z",
     "iopub.status.busy": "2025-10-13T05:20:37.559545Z",
     "iopub.status.idle": "2025-10-13T05:20:42.268932Z",
     "shell.execute_reply": "2025-10-13T05:20:42.268617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running /home/ascott/ascott_svn/SFSU/Fall_2025/research/IRTForests/.venv/bin/python /home/ascott/ascott_from_rey/ascott_svn/SFSU/Fall_2025/research/IRTForests/scripts/compute_rf_signals.py\n",
      "Margin stats: {'mean': -0.0027999996673315763, 'std': 0.10127430409193039, 'min': -0.4699999988079071, 'max': 0.4749999940395355, 'p05': -0.14000000059604645, 'p50': -0.014999999664723873, 'p95': 0.18000000715255737}\n",
      "Entropy stats: {'mean': 2.1503257751464844, 'std': 0.1330527663230896, 'min': 1.3168445825576782, 'max': 2.2915682792663574, 'p05': 1.897573471069336, 'p50': 2.191293239593506, 'p95': 2.2679343223571777}\n",
      "Running /home/ascott/ascott_svn/SFSU/Fall_2025/research/IRTForests/.venv/bin/python /home/ascott/ascott_from_rey/ascott_svn/SFSU/Fall_2025/research/IRTForests/scripts/analyze_rf_irt_correlations.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"margin\": {\n",
      "    \"pearson\": -0.8286201375113925,\n",
      "    \"spearman\": -0.7914636941712078\n",
      "  },\n",
      "  \"entropy\": {\n",
      "    \"pearson\": 0.6781969132131275,\n",
      "    \"spearman\": 0.5547502237696813\n",
      "  }\n",
      "}\n",
      "Running /home/ascott/ascott_svn/SFSU/Fall_2025/research/IRTForests/.venv/bin/python /home/ascott/ascott_from_rey/ascott_svn/SFSU/Fall_2025/research/IRTForests/scripts/plot_wright_map.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running /home/ascott/ascott_svn/SFSU/Fall_2025/research/IRTForests/.venv/bin/python /home/ascott/ascott_from_rey/ascott_svn/SFSU/Fall_2025/research/IRTForests/scripts/visualize_difficulty_extremes.py --split test --count 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote montages: figures/hardest_items_test.png and figures/easiest_items_test.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running /home/ascott/ascott_svn/SFSU/Fall_2025/research/IRTForests/.venv/bin/python /home/ascott/ascott_from_rey/ascott_svn/SFSU/Fall_2025/research/IRTForests/scripts/class_difficulty_summary.py\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_name  difficulty_mean  difficulty_std  difficulty_median  rf_accuracy  rf_error\n",
      "0         cat         7.775689        2.210995           7.805991        0.225     0.775\n",
      "1       horse         7.038407        3.043636           7.495646        0.395     0.605\n",
      "2         dog         6.912098        3.268856           7.569791        0.330     0.670\n",
      "3        bird         6.617264        3.303873           7.019292        0.280     0.720\n",
      "4  automobile         5.944391        3.309684           6.356369        0.560     0.440\n",
      "5        frog         5.667435        3.643229           5.993254        0.450     0.550\n",
      "6       truck         5.499222        3.716035           5.775341        0.485     0.515\n",
      "7        deer         5.445076        4.940455           6.951806        0.440     0.560\n",
      "8    airplane         4.153870        5.345294           5.041322        0.545     0.455\n",
      "9        ship         3.946263        5.357770           4.840855        0.595     0.405\n",
      "All analytics scripts completed.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = PROJECT_ROOT\n",
    "scripts = project_root / \"scripts\"\n",
    "\n",
    "commands = [\n",
    "    [sys.executable, str(scripts / \"compute_rf_signals.py\")],\n",
    "    [sys.executable, str(scripts / \"analyze_rf_irt_correlations.py\")],\n",
    "    [sys.executable, str(scripts / \"plot_wright_map.py\")],\n",
    "    [sys.executable, str(scripts / \"visualize_difficulty_extremes.py\"), \"--split\", \"test\", \"--count\", \"10\"],\n",
    "    [sys.executable, str(scripts / \"class_difficulty_summary.py\")],\n",
    "]\n",
    "\n",
    "for cmd in commands:\n",
    "    print(\"Running\", \" \".join(cmd))\n",
    "    completed = subprocess.run(cmd, cwd=project_root)\n",
    "    if completed.returncode != 0:\n",
    "        raise RuntimeError(f\"Command failed: {' '.join(cmd)}\")\n",
    "print(\"All analytics scripts completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "658cc980",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:20:42.270074Z",
     "iopub.status.busy": "2025-10-13T05:20:42.269985Z",
     "iopub.status.idle": "2025-10-13T05:20:44.126587Z",
     "shell.execute_reply": "2025-10-13T05:20:44.126283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running /home/ascott/ascott_svn/SFSU/Fall_2025/research/IRTForests/.venv/bin/python /home/ascott/ascott_from_rey/ascott_svn/SFSU/Fall_2025/research/IRTForests/scripts/plot_additional_diagnostics.py --data-dir /home/ascott/ascott_from_rey/ascott_svn/SFSU/Fall_2025/research/IRTForests/data --figures-dir /home/ascott/ascott_from_rey/ascott_svn/SFSU/Fall_2025/research/IRTForests/figures --label Study I: CIFAR (PCA)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running /home/ascott/ascott_svn/SFSU/Fall_2025/research/IRTForests/.venv/bin/python /home/ascott/ascott_from_rey/ascott_svn/SFSU/Fall_2025/research/IRTForests/scripts/plot_additional_diagnostics.py --data-dir /home/ascott/ascott_from_rey/ascott_svn/SFSU/Fall_2025/research/IRTForests/data/mobilenet --figures-dir /home/ascott/ascott_from_rey/ascott_svn/SFSU/Fall_2025/research/IRTForests/figures/mobilenet --label Study II: CIFAR (MobileNet)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running /home/ascott/ascott_svn/SFSU/Fall_2025/research/IRTForests/.venv/bin/python /home/ascott/ascott_from_rey/ascott_svn/SFSU/Fall_2025/research/IRTForests/scripts/plot_additional_diagnostics.py --data-dir /home/ascott/ascott_from_rey/ascott_svn/SFSU/Fall_2025/research/IRTForests/data/mnist --figures-dir /home/ascott/ascott_from_rey/ascott_svn/SFSU/Fall_2025/research/IRTForests/figures/mnist --label Study III: MNIST Mini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional diagnostics complete.\n"
     ]
    }
   ],
   "source": [
    "# Regenerate ability/error scatter plots for each study run\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "diagnostics_script = PROJECT_ROOT / \"scripts\" / \"plot_additional_diagnostics.py\"\n",
    "\n",
    "diagnostic_jobs = [\n",
    "    (\"Study I: CIFAR (PCA)\", PROJECT_ROOT / \"data\", PROJECT_ROOT / \"figures\"),\n",
    "    (\"Study II: CIFAR (MobileNet)\", PROJECT_ROOT / \"data\" / \"mobilenet\", PROJECT_ROOT / \"figures\" / \"mobilenet\"),\n",
    "    (\"Study III: MNIST Mini\", PROJECT_ROOT / \"data\" / \"mnist\", PROJECT_ROOT / \"figures\" / \"mnist\"),\n",
    "]\n",
    "\n",
    "for label, data_dir, figures_dir in diagnostic_jobs:\n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        str(diagnostics_script),\n",
    "        \"--data-dir\",\n",
    "        str(data_dir),\n",
    "        \"--figures-dir\",\n",
    "        str(figures_dir),\n",
    "        \"--label\",\n",
    "        label,\n",
    "    ]\n",
    "    print(\"Running\", \" \".join(cmd))\n",
    "    completed = subprocess.run(cmd, cwd=PROJECT_ROOT)\n",
    "    if completed.returncode != 0:\n",
    "        raise RuntimeError(f\"Command failed: {' '.join(cmd)}\")\n",
    "print(\"Additional diagnostics complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb650f9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T05:20:44.127618Z",
     "iopub.status.busy": "2025-10-13T05:20:44.127516Z",
     "iopub.status.idle": "2025-10-13T05:20:44.138785Z",
     "shell.execute_reply": "2025-10-13T05:20:44.138598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>difficulty_mean</th>\n",
       "      <th>difficulty_std</th>\n",
       "      <th>difficulty_median</th>\n",
       "      <th>rf_accuracy</th>\n",
       "      <th>rf_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat</td>\n",
       "      <td>7.775689</td>\n",
       "      <td>2.210995</td>\n",
       "      <td>7.805991</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>horse</td>\n",
       "      <td>7.038407</td>\n",
       "      <td>3.043636</td>\n",
       "      <td>7.495646</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dog</td>\n",
       "      <td>6.912098</td>\n",
       "      <td>3.268856</td>\n",
       "      <td>7.569791</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bird</td>\n",
       "      <td>6.617264</td>\n",
       "      <td>3.303873</td>\n",
       "      <td>7.019292</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>automobile</td>\n",
       "      <td>5.944391</td>\n",
       "      <td>3.309684</td>\n",
       "      <td>6.356369</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>frog</td>\n",
       "      <td>5.667435</td>\n",
       "      <td>3.643229</td>\n",
       "      <td>5.993254</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>truck</td>\n",
       "      <td>5.499222</td>\n",
       "      <td>3.716035</td>\n",
       "      <td>5.775341</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deer</td>\n",
       "      <td>5.445076</td>\n",
       "      <td>4.940455</td>\n",
       "      <td>6.951806</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>airplane</td>\n",
       "      <td>4.153870</td>\n",
       "      <td>5.345294</td>\n",
       "      <td>5.041322</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ship</td>\n",
       "      <td>3.946263</td>\n",
       "      <td>5.357770</td>\n",
       "      <td>4.840855</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_name  difficulty_mean  difficulty_std  difficulty_median  \\\n",
       "0         cat         7.775689        2.210995           7.805991   \n",
       "1       horse         7.038407        3.043636           7.495646   \n",
       "2         dog         6.912098        3.268856           7.569791   \n",
       "3        bird         6.617264        3.303873           7.019292   \n",
       "4  automobile         5.944391        3.309684           6.356369   \n",
       "5        frog         5.667435        3.643229           5.993254   \n",
       "6       truck         5.499222        3.716035           5.775341   \n",
       "7        deer         5.445076        4.940455           6.951806   \n",
       "8    airplane         4.153870        5.345294           5.041322   \n",
       "9        ship         3.946263        5.357770           4.840855   \n",
       "\n",
       "   rf_accuracy  rf_error  \n",
       "0        0.225     0.775  \n",
       "1        0.395     0.605  \n",
       "2        0.330     0.670  \n",
       "3        0.280     0.720  \n",
       "4        0.560     0.440  \n",
       "5        0.450     0.550  \n",
       "6        0.485     0.515  \n",
       "7        0.440     0.560  \n",
       "8        0.545     0.455  \n",
       "9        0.595     0.405  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "report_dir = PROJECT_ROOT / \"reports\"\n",
    "report_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "data_dir = PROJECT_ROOT / \"data\"\n",
    "class_summary_path = data_dir / \"class_difficulty_summary.json\"\n",
    "class_summary = pd.read_json(class_summary_path)\n",
    "class_summary.to_markdown(report_dir / \"class_difficulty_summary.md\", index=False)\n",
    "\n",
    "with open(data_dir / \"rf_signal_summary.json\", \"r\", encoding=\"utf-8\") as fh:\n",
    "    signal_summary = json.load(fh)\n",
    "with open(data_dir / \"rf_irt_correlations.json\", \"r\", encoding=\"utf-8\") as fh:\n",
    "    correlation_summary = json.load(fh)\n",
    "\n",
    "summary_payload = {\n",
    "    \"rf_signal_summary\": signal_summary,\n",
    "    \"rf_irt_correlations\": correlation_summary,\n",
    "}\n",
    "\n",
    "with open(report_dir / \"rf_irt_summary.json\", \"w\", encoding=\"utf-8\") as fh:\n",
    "    json.dump(summary_payload, fh, indent=2)\n",
    "\n",
    "class_summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv) IRTForests",
   "language": "python",
   "name": "irtforests"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
