{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9301c25",
   "metadata": {},
   "source": [
    "# Random Forest × IRT Study\n",
    "\n",
    "This notebook walks through data preparation, model training, and Item Response Theory analysis for the CIFAR-10 subset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06d7d36",
   "metadata": {},
   "source": [
    "## 0. Setup\n",
    "\n",
    "Import libraries, define configuration, and set deterministic seeds for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae4be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "DATA_ROOT = Path('../data')\n",
    "CACHE_DIR = DATA_ROOT\n",
    "FIGURES_DIR = Path('../figures')\n",
    "MODELS_DIR = Path('../models')\n",
    "SUBSET_ARCHIVE = CACHE_DIR / 'cifar10_subset.npz'\n",
    "EMBEDDINGS_ARCHIVE = CACHE_DIR / 'cifar10_embeddings.npz'\n",
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# TODO: when executing, ensure directories exist before writing outputs.\n",
    "# FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "# MODELS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0928909",
   "metadata": {},
   "source": [
    "## 1. Data Download & Subsampling\n",
    "\n",
    "Use the helper routines in `src.data_pipeline` to ensure CIFAR-10 is downloaded and stratified into manageable train/val/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67428c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_pipeline import SubsetConfig, save_cifar10_subset\n",
    "\n",
    "subset_config = SubsetConfig(data_root=CACHE_DIR)\n",
    "if not SUBSET_ARCHIVE.exists():\n",
    "    subset_archive = save_cifar10_subset(subset_config)\n",
    "else:\n",
    "    subset_archive = SUBSET_ARCHIVE\n",
    "subset_archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ecdec",
   "metadata": {},
   "source": [
    "## 2. Embedding Pipeline\n",
    "\n",
    "Flatten the cached tensors and project to a compact latent space with PCA to serve as Random Forest inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e9b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_pipeline import compute_pca_embeddings\n",
    "\n",
    "if not EMBEDDINGS_ARCHIVE.exists():\n",
    "    embeddings_path, embedding_summary = compute_pca_embeddings(subset_archive)\n",
    "else:\n",
    "    embeddings_path, embedding_summary = EMBEDDINGS_ARCHIVE, {\n",
    "        'train_embeddings': None,\n",
    "        'val_embeddings': None,\n",
    "        'test_embeddings': None,\n",
    "        'explained_variance_ratio': None,\n",
    "    }\n",
    "embedding_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fa1c12",
   "metadata": {},
   "source": [
    "## 3. Random Forest Training\n",
    "\n",
    "Train a baseline `RandomForestClassifier` on the PCA embeddings and capture core metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f8564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "embeddings = np.load(embeddings_path)\n",
    "X_train = embeddings['train_embeddings']\n",
    "X_val = embeddings['val_embeddings']\n",
    "X_test = embeddings['test_embeddings']\n",
    "y_train = embeddings['y_train']\n",
    "y_val = embeddings['y_val']\n",
    "y_test = embeddings['y_test']\n",
    "\n",
    "# TODO (execution phase): optionally standardize embeddings.\n",
    "# if not embeddings.get('whitened', False):\n",
    "#     scaler = StandardScaler().fit(X_train)\n",
    "#     X_train = scaler.transform(X_train)\n",
    "#     X_val = scaler.transform(X_val)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "#     np.savez(CACHE_DIR / 'embedding_scaler.npz', mean_=scaler.mean_, scale_=scaler.scale_)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=SEED,\n",
    "    oob_score=True,\n",
    ")\n",
    "\n",
    "# Execution checklist (leave commented until ready):\n",
    "# 1. rf.fit(X_train, y_train)\n",
    "# 2. y_pred = rf.predict(X_test)\n",
    "# 3. probas = rf.predict_proba(X_test)\n",
    "# 4. metrics = {\n",
    "#        'overall_accuracy': float(accuracy_score(y_test, y_pred)),\n",
    "#        'oob_accuracy': float(rf.oob_score_),\n",
    "#        'val_accuracy': float(accuracy_score(y_val, rf.predict(X_val))),\n",
    "#        'per_class_accuracy': accuracy_score(y_test, y_pred, normalize=False)  # adjust to per-class table\n",
    "#    }\n",
    "# 5. conf_mat = confusion_matrix(y_test, y_pred)\n",
    "# 6. permutation = permutation_importance(\n",
    "#        rf, X_val, y_val, n_repeats=10, random_state=SEED, n_jobs=-1\n",
    "#    )\n",
    "# 7. persist metrics/arrays to CACHE_DIR / 'rf_metrics.json' and 'rf_confusion.npy'.\n",
    "# 8. dump feature importances & permutation results for slide consumption.\n",
    "\n",
    "# Suggested persistence stub:\n",
    "# metrics_payload = {\n",
    "#     'metrics': metrics,\n",
    "#     'classes': embeddings['classes'].tolist(),\n",
    "#     'feature_importances': rf.feature_importances_.tolist(),\n",
    "# }\n",
    "# (CACHE_DIR / 'rf_metrics.json').write_text(json.dumps(metrics_payload, indent=2))\n",
    "# np.save(CACHE_DIR / 'rf_confusion.npy', conf_mat)\n",
    "# permutation_df = pd.DataFrame(\n",
    "#     {'feature': np.arange(permutation.importances_mean.size),\n",
    "#      'importances_mean': permutation.importances_mean,\n",
    "#      'importances_std': permutation.importances_std}\n",
    "# )\n",
    "# permutation_df.to_csv(CACHE_DIR / 'rf_permutation_importance.csv', index=False)\n",
    "\n",
    "# Visualization hook (to be run later):\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig, ax = plt.subplots(figsize=(6, 5))\n",
    "# sns.heatmap(conf_mat / conf_mat.sum(axis=1, keepdims=True), annot=True, fmt='.2f', ax=ax)\n",
    "# ax.set_title('Random Forest Confusion Matrix (Normalized)')\n",
    "# ax.set_xlabel('Predicted')\n",
    "# ax.set_ylabel('True')\n",
    "# fig.tight_layout()\n",
    "# fig_path = FIGURES_DIR / 'rf_confusion_matrix.png'\n",
    "# FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "# fig.savefig(fig_path, dpi=200)\n",
    "# plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36404428",
   "metadata": {},
   "source": [
    "## 4. Response Matrix Construction\n",
    "\n",
    "Collect per-tree predictions on the test split to assemble the binary response matrix `R`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f35d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Response matrix utility --------------------------------------------------\n",
    "# TODO: ensure RF is trained before running this section.\n",
    "# response_matrix shape: (n_trees, n_test_examples)\n",
    "# Each entry is 1 if estimator predicts correctly, else 0.\n",
    "\n",
    "def build_response_matrix(rf_model, X, y_true):\n",
    "    \"\"\"Return binary matrix of estimator correctness for each test example.\"\"\"\n",
    "    responses = []\n",
    "    for estimator in rf_model.estimators_:\n",
    "        preds = estimator.predict(X)\n",
    "        responses.append((preds == y_true).astype(np.uint8))\n",
    "    return np.stack(responses)\n",
    "\n",
    "# Execution plan (commented for now):\n",
    "# R = build_response_matrix(rf, X_test, y_test)\n",
    "# response_path = CACHE_DIR / 'response_matrix.npz'\n",
    "# np.savez(response_path, R=R, y_test=y_test, classes=embeddings['classes'])\n",
    "# Wright-map compatible summary stats:\n",
    "# item_accuracy = R.mean(axis=0)\n",
    "# tree_accuracy = R.mean(axis=1)\n",
    "# summary = {\n",
    "#     'item_accuracy': item_accuracy.tolist(),\n",
    "#     'tree_accuracy': tree_accuracy.tolist(),\n",
    "# }\n",
    "# (CACHE_DIR / 'response_summary.json').write_text(json.dumps(summary, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c4ce4",
   "metadata": {},
   "source": [
    "## 5. IRT Fitting\n",
    "\n",
    "Fit a Rasch (1PL) model using the response matrix to estimate tree ability (θ) and item difficulty (δ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a426c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRT fitting checklist ----------------------------------------------------\n",
    "# Preferred library: py_irt (fallback: pyirt). Expect binary matrix input.\n",
    "# Example workflow once R is available:\n",
    "# from py_irt.irt import irt_1pl\n",
    "# model = irt_1pl(R)\n",
    "# tree_ability = model['theta']           # shape (n_trees,)\n",
    "# item_difficulty = model['delta']        # shape (n_items,)\n",
    "# discrimination = model.get('a')         # optional for 2PL\n",
    "# log_likelihood = model.get('loglik')\n",
    "#\n",
    "# Diagnostics to capture:\n",
    "# - Convergence flag / iterations\n",
    "# - Mean/std of θ and δ\n",
    "# - Histogram-ready arrays saved to CACHE_DIR / 'irt_parameters.npz'\n",
    "#\n",
    "# Suggested persistence stub:\n",
    "# np.savez(\n",
    "#     CACHE_DIR / 'irt_parameters.npz',\n",
    "#     theta=tree_ability,\n",
    "#     delta=item_difficulty,\n",
    "#     a=discrimination,\n",
    "#     meta={'loglik': log_likelihood}\n",
    "# )\n",
    "# Additionally, emit JSON summary for slides/reporting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bab86f6",
   "metadata": {},
   "source": [
    "## 6. Comparative Analysis\n",
    "\n",
    "Contrast IRT parameters with Random Forest margins, feature importances, and error patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27eceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute correlations, Wright map visualization, and hard example list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f0c321",
   "metadata": {},
   "source": [
    "## 7. Slide Export\n",
    "\n",
    "Append generated plots and key findings to `slides.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc25bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: once RF + IRT outputs are ready, assemble comparison plots.\n",
    "# Suggested steps:\n",
    "# 1. Compute RF margin per example from `probas` gathered above (p_true - max_other).\n",
    "#    margins = probas[np.arange(len(y_test)), y_test] - np.max(np.where(one_hot_indices != y_test[:, None], probas, -np.inf), axis=1)\n",
    "# 2. Build a dataframe with columns ['delta', 'margin', 'entropy', 'class', 'hard_example_flag'].\n",
    "# 3. Correlate item difficulty δ with margin, entropy, per-class error, and RF confidence.\n",
    "#    store both Pearson and Spearman correlations in CACHE_DIR / 'correlations.json'.\n",
    "# 4. Produce Wright map with matplotlib/seaborn; save to FIGURES_DIR / 'wright_map.png'.\n",
    "#    Example: twin histogram or scatter aligning θ (trees) on top axis and δ (items) on bottom axis.\n",
    "# 5. Surface top-10 hardest items (largest δ) along with thumbnails (use original tensors).\n",
    "#    Persist indices to CACHE_DIR / 'hard_items.json' and copy images to FIGURES_DIR / hard_examples/.\n",
    "# 6. Summarize findings in dictionaries to feed slides export and README logs.\n",
    "# 7. Persist correlation table to CSV for reproducibility; include ranking of trees/items by ability/difficulty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7a3068",
   "metadata": {},
   "source": [
    "## New analytics: RF margins, δ correlations, visuals\n",
    "\n",
    "Run helper scripts to compute RF per-item signals, correlate them with IRT difficulty, and emit supporting figures (difficulty vs margin/entropy, Wright map, hardest/easiest montages, class difficulty summary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e89f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "scripts = project_root / \"scripts\"\n",
    "\n",
    "commands = [\n",
    "    [sys.executable, str(scripts / \"compute_rf_signals.py\")],\n",
    "    [sys.executable, str(scripts / \"analyze_rf_irt_correlations.py\")],\n",
    "    [sys.executable, str(scripts / \"plot_wright_map.py\")],\n",
    "    [sys.executable, str(scripts / \"visualize_difficulty_extremes.py\"), \"--split\", \"test\", \"--count\", \"10\"],\n",
    "    [sys.executable, str(scripts / \"class_difficulty_summary.py\")],\n",
    "]\n",
    "\n",
    "for cmd in commands:\n",
    "    print(\"Running\", \" \".join(cmd))\n",
    "    completed = subprocess.run(cmd, cwd=project_root)\n",
    "    if completed.returncode != 0:\n",
    "        raise RuntimeError(f\"Command failed: {' '.join(cmd)}\")\n",
    "print(\"All analytics scripts completed.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
